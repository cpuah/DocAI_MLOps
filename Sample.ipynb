{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Document Intelligence Custom Template User Feedback Loop Experiment\n",
    "\n",
    "This experiment demonstrates how to replicate the functionality of the [Azure AI Document Intelligence](https://learn.microsoft.com/en-GB/azure/ai-services/document-intelligence/overview) Studio custom model training process to showcase how to create a user feedback loop for improving the quality of document processing results.\n",
    "\n",
    "This notebook showcases a more interactive user feedback experience, enabling a user to draw over an uploaded, analyzed document to provide feedback on the quality of results by highlighting incorrect or missing information with corrections. This implementation could be replicated in any client application using your chosen framework capabilities.\n",
    "\n",
    "The goal is to showcase how a feedback mechanism can be implemented to allow the developers of custom models in Azure AI Document Intelligence to collect feedback from users to improve the model with the ability to retrain.\n",
    "\n",
    "> **Note**: This notebook provides _one_ potential approach to user interaction, and can be interpreted in many ways based on your use case.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "> **Note**: Before continuing, please ensure that the [`Deploy-Infrastructure.ps1`](./Deploy-Infrastructure.ps1) script has been run to deploy the required infrastructure to Azure. This includes the Azure AI Document Intelligence resource and the Azure Storage account for creating a custom model.\n",
    "\n",
    "This notebook uses [Dev Containers](https://code.visualstudio.com/docs/remote/containers) to ensure that all the required dependencies are available in a consistent local development environment.\n",
    "\n",
    "The following are required to run this notebook:\n",
    "\n",
    "- [Visual Studio Code](https://code.visualstudio.com/)\n",
    "- [Docker Desktop](https://www.docker.com/products/docker-desktop)\n",
    "- [Remote - Containers extension for Visual Studio Code](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)\n",
    "\n",
    "> **Note**: The Dev Container is pre-configured with the required dependencies and extensions. You can run this notebook outside of a Dev Container, but you will need to manually install the required dependencies including Poppler, Tesseract, and OpenCV.\n",
    "\n",
    "The Dev Container will include the following dependencies by default:\n",
    "\n",
    "- Debian 11 (Bullseye) base image\n",
    "- Python 3.12\n",
    "  - azure-ai-formrecognizer - for interacting with the Azure AI Document Intelligence service\n",
    "  - azure-core - for interacting with the Azure AI Document Intelligence service\n",
    "  - ipycanvas - for rendering the document and allowing the user to draw over it\n",
    "  - ipykernel - for running the notebook\n",
    "  - notebook - for running the notebook\n",
    "  - opencv-python-headless - for image processing\n",
    "  - pdf2image - for converting PDFs to images\n",
    "  - pytesseract - for performing OCR on the document\n",
    "- Poppler - used by pdf2image to convert PDFs to images\n",
    "- Tesseract OCR - used by pytesseract to perform OCR on the document\n",
    "- Python3 OpenCV - used for image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Document Intelligence Custom Model\n",
    "\n",
    "In order to improve a model, you need to have one. This experiment comes prepared with the data required to train a custom model. The data is located in the [`model_training`](./model_training/) directory and contains a set of invoices that will be used by the following steps.\n",
    "\n",
    "The steps below perform the following:\n",
    "\n",
    "- Initialize local environment variables based on the output of the `Deploy-Infrastructure.ps1` script run. The environment variables will be available in the [`config.env`](./config.env) file.\n",
    "- Create a model training client (using the provided class) and run it to upload the files to Azure Blob Storage, and training the model using Azure AI Document Intelligence.\n",
    "\n",
    "> **Note**: The `Deploy-Infrastructure.ps1` script is not run as part of this notebook. It must be run separately, prior to running this notebook, to deploy the required infrastructure to Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from azure.ai.formrecognizer import (DocumentModelAdministrationClient, ModelBuildMode, DocumentAnalysisClient, AnalyzeResult)\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.storage.blob import BlobServiceClient, ContainerSasPermissions, generate_container_sas\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "working_dir = os.path.abspath('')\n",
    "config = dotenv_values(f\"{working_dir}/config.env\")\n",
    "\n",
    "model_name = 'invoices'\n",
    "initial_model_version = '1.0.0'\n",
    "\n",
    "initial_model_id = f\"{model_name}-{initial_model_version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainingClient:\n",
    "    def __init__(self, config):\n",
    "        document_intelligence_endpoint = config['AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT']\n",
    "        document_intelligence_key = config['AZURE_DOCUMENT_INTELLIGENCE_KEY']\n",
    "        storage_connection_string = config['AZURE_STORAGE_ACCOUNT_CONNECTION_STRING']\n",
    "        training_data_container_name = config['AZURE_DOCUMENT_INTELLIGENCE_TRAINING_DATA_CONTAINER_NAME']\n",
    "\n",
    "        blob_service_client = BlobServiceClient.from_connection_string(storage_connection_string)\n",
    "\n",
    "        self.storage_account_key = config['AZURE_STORAGE_ACCOUNT_KEY']\n",
    "        self.training_data_container_client = blob_service_client.get_container_client(training_data_container_name)\n",
    "        self.document_model_admin_client = DocumentModelAdministrationClient(endpoint=document_intelligence_endpoint, credential=AzureKeyCredential(document_intelligence_key))\n",
    "        self.document_analysis_client = DocumentAnalysisClient(endpoint=document_intelligence_endpoint, credential=AzureKeyCredential(document_intelligence_key))\n",
    "\n",
    "    def upload_training_data(self, training_data_folder_path):\n",
    "        for root, _, files in os.walk(training_data_folder_path):\n",
    "            for file in files:\n",
    "                blob_client = self.training_data_container_client.get_blob_client(file)\n",
    "                with open(f\"{root}/{file}\", \"rb\") as data:\n",
    "                    blob_client.upload_blob(data, overwrite=True)\n",
    "\n",
    "        start_time = datetime.datetime.now(datetime.timezone.utc) - datetime.timedelta(minutes=5)\n",
    "        expiry_time = start_time + datetime.timedelta(days=1)\n",
    "\n",
    "        sas_token = generate_container_sas(\n",
    "            account_name=blob_client.account_name,\n",
    "            container_name=blob_client.container_name,\n",
    "            account_key=self.storage_account_key,\n",
    "            permission=ContainerSasPermissions(read=True, list=True),\n",
    "            expiry=expiry_time,\n",
    "            start=start_time\n",
    "        )\n",
    "\n",
    "        self.training_data_container_client_sas_url = f\"{self.training_data_container_client.url}?{sas_token}\"        \n",
    "    \n",
    "    def create_model(self, model_name):\n",
    "        try:\n",
    "            self.document_model_admin_client.delete_document_model(model_name)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        poller = self.document_model_admin_client.begin_build_document_model(\n",
    "            build_mode=ModelBuildMode.TEMPLATE,\n",
    "            blob_container_url=self.training_data_container_client_sas_url,\n",
    "            model_id=model_name\n",
    "        )\n",
    "        self.model = poller.result()\n",
    "        return self.model\n",
    "    \n",
    "    def run_layout_analysis(self, file_path):\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            poller = self.document_analysis_client.begin_analyze_document(model_id='prebuilt-layout', document=f)\n",
    "            self.analysis_result = poller.result()\n",
    "        return self.analysis_to_json(self.analysis_result)\n",
    "\n",
    "    def analysis_to_json(self, analysis_result: AnalyzeResult):\n",
    "        date = datetime.datetime.now(datetime.UTC).__format__('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "        return {\n",
    "            \"status\": \"succeeded\",\n",
    "            \"createdDateTime\": date,\n",
    "            \"lastUpdatedDateTime\": date,\n",
    "            \"analyzeResult\": analysis_result.to_dict()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_client = ModelTrainingClient(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload initial training data and create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_client.upload_training_data(f\"{working_dir}/model_training\")\n",
    "invoice_model = model_training_client.create_model(model_name=initial_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Feedback Setup\n",
    "\n",
    "The following will setup the required imports and constants for the notebook, including the path to the sample Invoice PDF that will be used, as well as creating the necessary paths to store the page image outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from ipycanvas import Canvas\n",
    "from ipywidgets import Image, Dropdown, Text, VBox, Label\n",
    "import pytesseract\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "pdf_file_name = 'Invoice_6.pdf'\n",
    "pdf_dir = os.path.join(working_dir, 'pdfs')\n",
    "pdf_path = os.path.join(pdf_dir, pdf_file_name)\n",
    "\n",
    "images_dir = os.path.join(working_dir, 'images')\n",
    "if not os.path.exists(images_dir):\n",
    "    os.makedirs(images_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define object for tracking feedback regions\n",
    "\n",
    "The following object is used to define the square border in which the user can draw over the document to provide feedback with. This object tracks the start and end coordinates of the border, as well as functions for performing the drawing of the border, normalizing the coordinates for the labels JSON output, and extracting the text within the border using OCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquareBorder:\n",
    "    def __init__(self, image_path_ref: str, page_ref: int, border_width=2, border_color='black'):\n",
    "        self.image_path_ref = image_path_ref\n",
    "        self.page_ref = page_ref\n",
    "        self.border_width = border_width\n",
    "        self.border_color = border_color\n",
    "        self.start_x = None\n",
    "        self.start_y = None\n",
    "        self.end_x = None\n",
    "        self.end_y = None\n",
    "\n",
    "    def start(self, x, y):\n",
    "        self.start_x = x\n",
    "        self.start_y = y\n",
    "\n",
    "    def end(self, x, y):\n",
    "        self.end_x = x\n",
    "        self.end_y = y\n",
    "\n",
    "    def draw(self, canvas: Canvas):\n",
    "        canvas.stroke_style = self.border_color\n",
    "        canvas.line_width = self.border_width\n",
    "        canvas.stroke_rect(self.start_x, self.start_y, self.end_x - self.start_x, self.end_y - self.start_y)\n",
    "        self.normalize(canvas)\n",
    "\n",
    "    def normalize(self, canvas: Canvas):\n",
    "        # normalize the square_border pixels 0..1\n",
    "        self.start_x_normalized = self.start_x / canvas.width\n",
    "        self.start_y_normalized = self.start_y / canvas.height\n",
    "        self.end_x_normalized = self.end_x / canvas.width\n",
    "        self.end_y_normalized = self.end_y / canvas.height\n",
    "\n",
    "    def extract_text(self):\n",
    "        try:\n",
    "            start_x_int = int(self.start_x)\n",
    "            start_y_int = int(self.start_y)\n",
    "            end_x_int = int(self.end_x)\n",
    "            end_y_int = int(self.end_y)\n",
    "\n",
    "            img = cv2.imread(self.image_path_ref)\n",
    "            crop_img = img[start_y_int:end_y_int, start_x_int:end_x_int]\n",
    "            return pytesseract.image_to_string(crop_img)\n",
    "        except:\n",
    "            return ''\n",
    "\n",
    "    def get_bounding_box(self):\n",
    "        return [(self.start_x, self.start_y), (self.end_x, self.end_y)]\n",
    "\n",
    "    def get_normalized_bounding_box(self):\n",
    "        return [self.start_x_normalized, self.start_y_normalized, self.end_x_normalized, self.start_y_normalized, self.end_x_normalized, self.end_y_normalized, self.start_x_normalized, self.end_y_normalized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the PDF document into view for user feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canvas handling class\n",
    "\n",
    "The code below defines a class that will handle the creation of the Canvas and handlers for mouse interaction events. This class will be used to create the canvas and handle the drawing of the feedback borders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_borders = []\n",
    "\n",
    "def handle_mouse_down_start_draw(canvas: Canvas, x, y):\n",
    "    square_border = SquareBorder(canvas.image_path_ref, canvas.page_ref)\n",
    "    square_border.start(x, y)\n",
    "    square_borders.append(square_border)\n",
    "\n",
    "def handle_mouse_down_end_draw(canvas: Canvas, x, y):\n",
    "    square_border = square_borders[-1]\n",
    "    square_border.end(x, y)\n",
    "    square_border.draw(canvas)\n",
    "\n",
    "def analyze_pdf(file_path: str):\n",
    "    layout_analysis = model_training_client.run_layout_analysis(file_path)\n",
    "    layout_analysis_path_ref = os.path.join(pdf_dir, f'{pdf_file_name}.ocr.json')\n",
    "    with open(layout_analysis_path_ref, 'w') as f:\n",
    "        json.dump(layout_analysis, f)\n",
    "\n",
    "def load_pdf(file_path: str):\n",
    "    pages = convert_from_path(file_path, fmt='jpeg')\n",
    "\n",
    "    print(f'Loaded {len(pages)} pages')\n",
    "\n",
    "    canvases = [Canvas(width=page.width, height=page.height) for page in pages]\n",
    "\n",
    "    for i, page in enumerate(pages):\n",
    "        page_ref = i + 1\n",
    "        image_path_ref = os.path.join(images_dir, f'{pdf_file_name}.page_{page_ref}.jpg')\n",
    "        page.save(image_path_ref, 'JPEG')\n",
    "    \n",
    "        canvases[i].image_path_ref = image_path_ref\n",
    "        canvases[i].page_ref = page_ref\n",
    "\n",
    "        canvases[i].draw_image(Image.from_file(image_path_ref), 0, 0, pages[i].width, pages[i].height)\n",
    "        canvases[i].on_mouse_down(lambda x, y: handle_mouse_down_start_draw(canvases[i], x, y))\n",
    "        canvases[i].on_mouse_up(lambda x, y: handle_mouse_down_end_draw(canvases[i], x, y))\n",
    "\n",
    "    return canvases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run layout analysis on the PDF document using Azure AI Document Intelligence\n",
    "\n",
    "This step will use the Azure AI Document Intelligence service to perform layout analysis on the PDF document. When complete, the analysis will be captured as a JSON object and stored in the `pdfs` folder using the name of the PDF with the additional suffix `.ocr.json`.\n",
    "\n",
    "> **Note**: This specific step does not need to be run every time. The layout analysis is only required to be run once to capture the initial state of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the PDF in the notebook for user feedback\n",
    "\n",
    "The following code will perform the following:\n",
    "\n",
    "1. Load the PDF document and store each page as an image using pdf2image.\n",
    "1. Display the rendered image using Canvas below as an interactive element in an output cell. **Note**: The image is rendered at the original size of the PDF page.\n",
    "1. Allow you to draw borders over the rendered image by clicking/holding, dragging, and releasing the mouse.\n",
    "\n",
    "Below is an example of this interaction in action.\n",
    "\n",
    "![Demonstration of canvas selection](./media/canvas-selection.gif)\n",
    "\n",
    "> **Note**: This simple demonstration does not allow drawn borders to be removed or edited once drawn. To start again, you will need to re-run the cell.\n",
    "\n",
    "As well as displaying the PDF, the required fields for the model are also displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_file_path = os.path.join(working_dir, 'model_training', 'fields.json')\n",
    "with open(fields_file_path, 'r') as f:\n",
    "    fields = json.load(f)\n",
    "\n",
    "display_fields = [Label(value=f'{field['fieldKey']}') for field in fields['fields']]\n",
    "display_container = VBox(display_fields)\n",
    "\n",
    "print('Fields to capture')\n",
    "display(display_container)\n",
    "\n",
    "canvases = load_pdf(pdf_path)\n",
    "canvases[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the user feedback into Document Intelligence labels format\n",
    "\n",
    "Once the user has drawn borders over the document to provide feedback, the following code will process the drawn borders into the labels JSON format used by the Azure AI Document Intelligence service. The files will be saved to the `./pdfs` directory with the name format `<pdf_file_name>.labels.json`.\n",
    "\n",
    "In a real-world scenario, the labels JSON files could be loaded into a UI to allow the user to update the label names associated with the custom model, and then retrain the model using the updated labels and PDF documents. For the purposes of this experiment, these are rendered as UI inputs in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Intelligence Label Class\n",
    "\n",
    "The following class is used to define the labels for the Azure AI Document Intelligence service and render the labels as UI inputs in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentIntelligenceLabel:\n",
    "    def __init__(self, border: SquareBorder, fields):\n",
    "        self.label = ''\n",
    "        self.field = ''\n",
    "        self.item_row_number = ''\n",
    "        self.item_row_field = ''\n",
    "        self.label_type = None\n",
    "        self.text = border.extract_text()\n",
    "        self.border = border\n",
    "        self.fields = fields\n",
    "\n",
    "        self.ui_field = None\n",
    "        self.ui_text = None\n",
    "        self.ui_bounding_box = None\n",
    "        self.ui_row_number = None\n",
    "        self.ui_row_field = None\n",
    "        self.ui_row_container = None\n",
    "        self.ui_container = None\n",
    "\n",
    "    def render(self):\n",
    "        field_options = ['']\n",
    "        for field in self.fields['fields']:\n",
    "            field_options.append(field['fieldKey'])\n",
    "\n",
    "        self.ui_field = Dropdown(\n",
    "            options=field_options,\n",
    "            description='Field:',\n",
    "            continuous_update=True\n",
    "        )\n",
    "        self.ui_field.observe(self.handle_field_change, names='value')\n",
    "\n",
    "        self.ui_text = Text(\n",
    "            value=self.text,\n",
    "            description='Text:',\n",
    "            continuous_update=True\n",
    "        )\n",
    "        self.ui_text.observe(self.handle_text_change, names='value')\n",
    "\n",
    "        self.ui_bounding_box = Label(value=f'Bounding Box: {self.border.get_bounding_box()}')\n",
    "\n",
    "        self.ui_container = VBox([self.ui_field, self.ui_text, self.ui_bounding_box])\n",
    "\n",
    "        return self.ui_container\n",
    "\n",
    "    def handle_field_change(self, change):\n",
    "        self.field = change.new\n",
    "\n",
    "        field_option = next((x for x in self.fields['fields'] if x['fieldKey'] == change.new), None)\n",
    "        if field_option:\n",
    "            if field_option['fieldType'] == \"array\":\n",
    "                itemType = field_option['itemType']\n",
    "                definition = self.fields['definitions'][itemType]\n",
    "\n",
    "                # Add a text box to the existing vbox for the row number\n",
    "                self.ui_row_number = Text(\n",
    "                    value='',\n",
    "                    description='Row Number:',\n",
    "                    continuous_update=True\n",
    "                )\n",
    "                self.ui_row_number.observe(self.handle_row_number_change, names='value')\n",
    "\n",
    "                row_field_options = ['']\n",
    "                for row_field in definition['fields']:\n",
    "                    row_field_options.append(row_field['fieldKey'])\n",
    "\n",
    "                self.ui_row_field = Dropdown(\n",
    "                    options=row_field_options,\n",
    "                    description='Row Field:',\n",
    "                    continuous_update=True\n",
    "                )\n",
    "                self.ui_row_field.observe(self.handle_row_field_change, names='value')\n",
    "\n",
    "                self.ui_row_container = VBox([self.ui_row_number, self.ui_row_field])\n",
    "                self.ui_container.children = self.ui_container.children + (self.ui_row_container,)\n",
    "            else:\n",
    "                self.label = self.field\n",
    "\n",
    "                if field_option['fieldType'] == \"signature\":\n",
    "                    self.label_type = \"region\"\n",
    "                else:\n",
    "                    self.label_type = None\n",
    "                \n",
    "                if self.ui_row_container is not None:\n",
    "                    self.ui_container.children = self.ui_container.children[:-1]\n",
    "                    self.ui_row_container = None\n",
    "\n",
    "    def handle_text_change(self, change):\n",
    "        self.text = change.new\n",
    "\n",
    "    def handle_row_number_change(self, change):\n",
    "        self.item_row_number = change.new\n",
    "        self.set_row_label()\n",
    "\n",
    "    def handle_row_field_change(self, change):\n",
    "        self.item_row_field = change.new\n",
    "        self.set_row_label()\n",
    "\n",
    "    def set_row_label(self):\n",
    "        self.label = f\"{self.field}/{self.item_row_number}/{self.item_row_field}\"\n",
    "\n",
    "    def as_label(self):\n",
    "        label_json = {\n",
    "            \"label\": self.label, \n",
    "            \"value\": [\n",
    "                {\n",
    "                    \"page\": self.border.page_ref,\n",
    "                    \"text\": self.text,\n",
    "                    \"boundingBoxes\": [self.border.get_normalized_bounding_box()]\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "\n",
    "        if self.label_type is not None:\n",
    "            label_json['labelType'] = self.label_type\n",
    "\n",
    "        return label_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render the user feedback as UI inputs\n",
    "\n",
    "The following code will render the user feedback as UI inputs in the notebook as output. You can update the label names associated with the custom model.\n",
    "\n",
    "Each square border previously drawn over the document will be rendered as a UI input in the notebook. The fields will be pre-populated, and you will be able to select the label from the available options for the model, and update the text associated with the label.\n",
    "\n",
    "> **Note**: If the label option is an array, you will be provided with additional options to provide the row number and the column label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [DocumentIntelligenceLabel(border, fields) for border in square_borders]\n",
    "    \n",
    "for label in labels:\n",
    "    display(label.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the labels JSON file\n",
    "\n",
    "Once the user has updated the label names and text associated with the drawn borders, the following code will create the labels JSON file in the format required by the Azure AI Document Intelligence service. The file will be saved to the `./pdfs` directory with the name format `<pdf_file_name>.labels.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_json = {\n",
    "    \"$schema\": \"https://schema.cognitiveservices.azure.com/formrecognizer/2021-03-01/labels.json\",\n",
    "    \"document\": pdf_file_name,\n",
    "    \"labels\": [label.as_label() for label in labels]\n",
    "}\n",
    "\n",
    "labels_file_path = os.path.join(pdf_dir, f'{pdf_file_name}.labels.json')\n",
    "with open(labels_file_path, 'w') as f:\n",
    "    json.dump(labels_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain the model using the updated labels and PDF documents\n",
    "\n",
    "Once complete, the generated user feedback can be uploaded to the Azure Storage account and used to retrain the model using the Azure AI Document Intelligence service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_model_version = \"1.1.0\"\n",
    "updated_model_id = f\"{model_name}-{updated_model_version}\"\n",
    "\n",
    "model_training_client.upload_training_data(pdf_dir)\n",
    "updated_model = model_training_client.create_model(model_name=updated_model_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
